[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "You will find my course work on this website, please feel free to explore it!"
  },
  {
    "objectID": "Takehome_Exercise/Takehome_Exercise1/Takehome_Ex01.html",
    "href": "Takehome_Exercise/Takehome_Exercise1/Takehome_Ex01.html",
    "title": "TakeHome_Ex1",
    "section": "",
    "text": "Access to clean and abundant water is a vital necessity for human health and well-being. Adequate Clean water is crucial in promoting a healthy environment, sustaining economic growth in countries. However, a significant portion of the global population, including those in Nigeria, are still grappling with a lack of access to sufficient water resources. Given the critical role that water plays in many aspects of life, it is essential to understand the current water distribution system and identify potential areas for improvement.\n\n\n\nApply appropriate spatial point patterns analysis method to discover the geographical distribution of functional and non-function water points an and their co-locations\n\n\n\n\n\n\n\nThe package we used for analysis are:\n\nsf: For importing, managing and processing vector-based geospatial data\ntidyverse: For performing data science tasks such as importing, wrangling and visualising data.\ntmap: used for creating thematic maps, such as choropleth and bubble maps\nraster: reads, writes, manipulates, analyses and models gridded spatial data\nspatstat: used for point pattern analysis\nmaptools: a set of tools for manipulating geographic data\nfunModeling: used for exploratory data analysis\nsfdep: for performing geospatia data wrangling and local colocation quotient analysis.\n\nLet’s load the package required!\n\npacman::p_load(maptools, sf, raster, spatstat, tmap,tidyverse,plotly,funModeling,sfdep)\n\nHere are two possible datasets that we can obtain the geospatial information of Nigeria from, one is from Humanitarian Data Exchange portal, the other is from geoBoundaries, let’s read both of the datasets and examine which one is more suitable to use, notice that the crs for Nigeria should be 23692, so we need to assign the crs after reading the data:\n\ngeoNGA <- st_read(\"data/geospatial/\",\n                  layer = \"geoBoundaries-NGA-ADM2\") %>%\n  st_transform(crs = 26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\Quanfang777\\IS415-GAA\\Takehome_Exercise\\Takehome_Exercise1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\nNGA <- st_read(\"data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\Quanfang777\\IS415-GAA\\Takehome_Exercise\\Takehome_Exercise1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nAfter checking both sf dataframes, we notice that NGA provide both LGA and state information. Hence, NGA data.frame will be selected for the subsequent processing.\n\n\n\nAs our target is to analysis the water points in Osun State,Nigeria,(the area colored in red) so let’s filter the data and selected only the observations in Osun State, Nigeria\n\n(Fig1: Location of Osun State)\n\nwp_Osun <- read_csv(\"data/aspatial/WPdx.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\") %>%\n  filter (`#clean_adm1` == \"Osun\") \n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 406566 Columns: 70\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (43): #source, #report_date, #status_id, #water_source_clean, #water_sou...\ndbl (23): row_id, #lat_deg, #lon_deg, #install_year, #fecal_coliform_value, ...\nlgl  (4): #rehab_year, #rehabilitator, is_urban, latest_record\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n#Let's display the studyarea - Osun on the map:\nNGA_Osun <- NGA%>%\n  filter(`ADM1_EN` == \"Osun\")\n\nThen, let’s ensure that spatial data to be used for analysis has no invalid geometries.\n\nlength(which(st_is_valid(NGA_Osun) == FALSE))\n\n[1] 0\n\n\nPlot the basemap for osun, Nigeria to check if we obtain the value correctly\n\nosungraph = tmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(NGA_Osun)+tm_polygons()\n\n\n\n\nCompared to the map (Fig.1) we know that we have successfully obtained the geospatial information of Osun\n\n\n\n\n\n\nIn order to convert the point data into sf point feature for further analysis, first we need to convert the wkt field into sfc field by using st_as_sfc() data type.\n\nwp_Osun$Geometry = st_as_sfc(wp_Osun$`New Georeferenced Column`)\nwp_Osun\n\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nThen, use st_sf() to convert the tibble data.frame into sf object and also include the referencing system of the data into the sf object. ( Important, don’t forget to assign a crs when using st_sf)\n\nwp_Osun <- st_sf(wp_Osun, crs=4326)\nwp_Osun\n\nSimple feature collection with 5557 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4.032004 ymin: 7.060309 xmax: 5.06 ymax: 8.061898\nGeodetic CRS:  WGS 84\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nAfter assigning a crs to our sf object of wp_Osun, let’s transforming it into Nigeria projected coordinate system\n\nwp_Osun <- wp_Osun %>%\n  st_transform(crs = 26392)\n\nLet’s if the crs has been assigned properly!\n\nst_crs(wp_Osun)\n\nCoordinate Reference System:\n  User input: EPSG:26392 \n  wkt:\nPROJCRS[\"Minna / Nigeria Mid Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria Mid Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",8.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",670553.98,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria between 6°30'E and 10°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,6.5,13.53,10.51]],\n    ID[\"EPSG\",26392]]\n\n\n\n\n\n\n\n\nIt is always important for us to check for duplicate name in the data main data fields. Here are the steps of properly handling the duplication\n\n# Get all the duplicated LGA names\nduplicated_LGA <- NGA_Osun$ADM2_EN[duplicated(NGA_Osun$ADM2_EN)==TRUE]\n\n# Get all the indices with names that are included in the duplicated LGA names\nduplicated_indices <- which(NGA_Osun$ADM2_EN %in% duplicated_LGA)\n\n# For every index in the duplicated_indices, concatenate the two columns with a comma\nfor (ind in duplicated_indices) {\n  NGA_Osun$ADM2_EN[ind] <- paste(NGA_Osun$ADM2_EN[ind], NGA_Osun$ADM1_EN[ind], sep=\", \")\n}\n\nLet’s confirm if there is any duplication\n\nNGA_Osun$ADM2_EN[duplicated(NGA_Osun$ADM2_EN)==TRUE]\n\ncharacter(0)\n\n\nGreat, let’s moving on\n\n\n\nLet’s have a quick understanding of our water point data\n\nfreq(data = wp_Osun,\n     input = '#status_clean')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional      2319      41.73           41.73\n2                   Non-Functional      2008      36.13           77.86\n3                             <NA>       748      13.46           91.32\n4      Functional but needs repair       248       4.46           95.78\n5 Non-Functional due to dry season       151       2.72           98.50\n6        Functional but not in use        63       1.13           99.63\n7                        Abandoned        15       0.27           99.90\n8         Abandoned/Decommissioned         5       0.09          100.00\n\n\nWe can see that there are 9 classes in the #status_clean field, and there is a class called NA, for easy handling the subsequent steps and make it a more meaningful analysis, we can do following:\n\nRecode the NA values into unknown\nRemove the ‘#’ sign before the #status_clean field\n9 classes are a lot, and it is possible to combine them into 3 meaningful classes\n\n\n#recode the NA values into unknown and remove the '#'sign before #status_clean field\nwp_Osun <- wp_Osun  %>% \n  rename(status_clean = '#status_clean') %>%\n  select(status_clean) %>%\n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"))\n\n\n\n\nNow, let’s extract the water point data in Osun state according to their status.\nTo extract functional water point:\n\nwp_Osun_functional <- wp_Osun %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nTo extract non-functional water point:\n\nwp_Osun_nonfunctional <- wp_Osun %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\nTo extract water point with unknown status\n\nwp_Osun_unknown <- wp_Osun %>%\n  filter(status_clean == \"unknown\")\n\n\n\n\n\nFor displaying the kernel density maps, many geospatial analysis packages required need the input geospatial data to be in sp’s Spatial* classes, so we need to convert simple feature data frame to sp’s Spatial* class.\n\n\n\nwp_Osun_functional <- as_Spatial(wp_Osun_functional)\nwp_Osun_nonfunctional<- as_Spatial(wp_Osun_nonfunctional)\nNGA_Osun_sp <- as_Spatial(NGA_Osun)\n\n\n\n\nFor further analysis, we need spatstat which requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nSpatial classes-> Spatial object (Spatial classes usually contains more information than Spatial object, Spatial object only contains the spatial information so it has lesser time to process)\n\nwp_Osun_functional_sp <- as(wp_Osun_functional, \"SpatialPoints\")\nwp_Osun_nonfunctional_sp <- as(wp_Osun_nonfunctional, \"SpatialPoints\")\nNGA_Osun_sp<- as(NGA_Osun_sp, \"SpatialPolygons\")\n\n\n\n\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format, let’s do it for both functional and non-function waterpoint data\n\nwp_Osun_functional_ppp <- as(wp_Osun_functional, \"ppp\")\nwp_Osun_functional_ppp\n\nMarked planar point pattern: 2630 points\nmarks are of storage type  'character'\nwindow: rectangle = [177285.9, 290750.96] x [343128.1, 450859.7] units\n\n\n\nwp_Osun_nonfunctional_ppp <- as(wp_Osun_nonfunctional, \"ppp\")\nwp_Osun_nonfunctional_ppp\n\nMarked planar point pattern: 2179 points\nmarks are of storage type  'character'\nwindow: rectangle = [180538.96, 290616] x [340054.1, 450780.1] units\n\n\n\n\n\nIt is always important to check if there are duplicated points!\n\nany(duplicated(wp_Osun_functional_ppp))\n\n[1] FALSE\n\n\n\nany(duplicated(wp_Osun_nonfunctional_ppp))\n\n[1] FALSE\n\n\nThere is no duplication point, let’s moving on!\n\n\n\nWhen analysing spatial point patterns, it will be good to confine the analysis with a geographical area, in this case, let’s confine the analysis within Osun boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\n\nOsun_owin <- as(NGA_Osun_sp, \"owin\")\n\n\nplot(Osun_owin)\n\n\n\n\n\n\n\nNow, let’s combine both the point and polygon feature in ppp object class\n\nwp_Osun_functional_ppp = wp_Osun_functional_ppp[Osun_owin]\nwp_Osun_nonfunctional_ppp = wp_Osun_nonfunctional_ppp[Osun_owin]\n\n\n\n\nLet’s compute the Kernel Density map for both functional waterpoint and nonfunctional waterpoint in Osun\nLet’s use bw.diggle() to compute an ideal bandwidth selection method for us and use “gaussian” for our smoothing method\n\nkde_Osun_functional_bw<- density(wp_Osun_functional_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nkde_Osun_nonfunctional_bw<- density(wp_Osun_nonfunctional_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nplot(kde_Osun_functional_bw)\n\n\n\n\nThe density values of the output range from 0 to 0.00002 which is way too small to comprehend. This is because the default unit of measurement is in meter. As a result, the density values computed is in “number of points per square meter”. so, let’s rescale our KDE values\n\n\n\nLet’s convert the unit of measurement from meter to kilometer.\n\nwp_Osun_functional_ppp.km <- rescale(wp_Osun_functional_ppp, 1000, \"km\")\n\n\nwp_Osun_nonfunctional_ppp.km <- rescale(wp_Osun_nonfunctional_ppp, 1000, \"km\")\n\nNow, let’s plot the map after rescaling\n\nkde_Osun_functional.bw <- density(wp_Osun_functional_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_Osun_functional.bw)\n\n\n\n\n\nkde_Osun_nonfunctional.bw <- density(wp_Osun_nonfunctional_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_Osun_nonfunctional.bw)\n\n\n\n\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nThis is the code to compute adaptive bandwidth\n\nwp_Osun_functional_adaptive <- adaptive.density(wp_Osun_functional_ppp.km, method=\"kernel\")\nplot(wp_Osun_functional_adaptive)\n\n\n\n\n\nwp_Osun_nonfunctional_adaptive <- adaptive.density(wp_Osun_nonfunctional_ppp.km, method=\"kernel\")\nplot(wp_Osun_nonfunctional_adaptive)\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\n\n\n\npar(mfrow=c(1,2))\nplot(kde_Osun_functional.bw, main = \"Fixed bandwidth\")\nplot(wp_Osun_functional_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\nNonfunctional waterpoint distribution in fixed and adaptive kernel density estimation outputs\n\npar(mfrow=c(1,2))\nplot(kde_Osun_nonfunctional.bw, main = \"Fixed bandwidth\")\nplot(wp_Osun_nonfunctional_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\nWe need to convert the KDE output so that it is suitable for mapping purposes\n\nkde_functionalwp_raster <- kde_Osun_functional.bw  %>%\n  as.SpatialGridDataFrame.im() %>%\n  raster()\nkde_functionalwp_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -5.092436e-15, 25.49435  (min, max)\n\n\n\nkde_nonfunctionalwp_raster <- kde_Osun_nonfunctional.bw  %>%\n  as.SpatialGridDataFrame.im() %>%\n  raster()\nkde_nonfunctionalwp_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -3.925434e-15, 20.49412  (min, max)\n\n\n\n\n\n\nprojection(kde_functionalwp_raster) <- CRS('+init=EPSG:26392')\nprojection(kde_nonfunctionalwp_raster) <- CRS('+init=EPSG:26392')\nkde_functionalwp_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -5.092436e-15, 25.49435  (min, max)\n\nkde_nonfunctionalwp_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -3.925434e-15, 20.49412  (min, max)\n\n\n\n\n\nThe functional water point distribution\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_basemap('OpenStreetMap') +\ntm_shape(kde_functionalwp_raster) +\n  tm_raster('v') + \n  tm_layout(legend.position = c('right', 'bottom'), \n            frame = FALSE)\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\nVariable(s) \"v\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nThe nonfunctional water point distribution\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_basemap('OpenStreetMap') +\ntm_shape(kde_nonfunctionalwp_raster) +\n  tm_raster('v') + \n  tm_layout(legend.position = c('right', 'bottom'), \n            frame = FALSE)\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\nVariable(s) \"v\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nFrom the graph we can clearly see that the nonfunctional waterpoints are centered in the central region area (IFE Central). When compare these two maps above (functional waterpoint distribution and non functional waterpoint distribution), we found the north part of Osun has more functional waterpoints than the south part of Osun\n\n\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(NGA_Osun) + \n  tm_polygons() +\ntm_shape(wp_Osun)+ \n  tm_dots(col = \"status_clean\",\n             size = 0.01,\n             border.col = \"black\",\n             border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(8, 16))\n\n\n\n\n\n\nIt looks like the graph has too many colors and it will be better if we group them only in Functional, Nonfunctional, Unknown, so it will be clear to visualize\n\nwp_Osun <- wp_Osun %>%\n  mutate(status_group = recode(status_clean,\n                               \"Functional\" = \"Functional\",\n                               \"Functional but not in use\" = \"Functional\",\n                               \"Functional but needs repair\" = \"Functional\",\n                               \"Abandoned/Decommissioned\" = \"Nonfunctional\",\n                               \"Abandoned\" = \"Nonfunctional\",\n                               \"Non-Functional due to dry season\" = \"Nonfunctional\",\n                               \"Non-Functional\" = \"Nonfunctional\",\n                               \"Non functional due to dry season\" = \"Nonfunctional\",\n                               \"unknown\" = \"Unknown\"))\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(NGA_Osun) + \n  tm_polygons() +\ntm_shape(wp_Osun)+ \n  tm_dots(col = \"status_group\",\n             size = 0.01,\n             border.col = \"black\",\n             border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(8, 16))\n\n\n\n\n\n\n\nplot(kde_Osun_functional.bw, main = \"Functional Waterpoint\")\n\n\n\nplot(kde_Osun_nonfunctional.bw, main = \"Nonfunctional Waterpoint\")\n\n\n\n\nThe advantage of kernel density map over point map:\nKernel density map can provide us with a clear representation of the spatial data distribution. It provides a smooth representation of the underlying distribution and make sure the visualization of areas with a high concentration of points is clear, while point maps can be misleading because they may over-represent areas with many points and under-represent areas with fewer points. In our case, we can see when there are so many points on the graph of point map, it is very hard to observe and interpret.\n\n\n\n\nL function is a tool used to analyze spatial point patterns. It is a summary statistic that provides information on the spatial distribution of points.The L function can be used to identify clustering or regularity in the distribution of points, as well as to assess the spatial randomness of the point pattern.\nHere is the code to\n\n\n\n#to run this code, remove the'#'\n#L_ck = Lest(wp_Osun_functional_ppp, correction = \"Ripley\")\n#plot(L_ck, . -r ~ r, \n     #ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n#L_ck = Lest(wp_Osun_nonfunctional_ppp, correction = \"Ripley\")\n#plot(L_ck, . -r ~ r, \n     #ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n3.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of the functional/nonfunctional water point in Osun are randomly distributed.\nH1= The distribution of the functional/nonfunctional water point in Osun are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\nThe L function is a variance-stabilising transformation of the K function:\n\nMethodology and Interpretation\nTo assess the spatial point pattern, (L(r)−r) will be plotted against r\nAt complete spatial randomness (CSR), L(r)−r=0\nL(r)–r>0 implies clustering\nL(r)−r<0 implies dispersion\n\n#L_ck.csr <- envelope(wp_Osun_functional_ppp, Lest, nsim = 5, rank = 1, glocal=TRUE)\n\n\n#plot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n#L_ck.csr <- envelope(wp_Osun_nonfunctional_ppp, Lest, nsim = 5, rank = 1, glocal=TRUE)\n\n\n#plot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\nThe L(r)−r function for both functional and nonfunctional water points in Osun (black line) lies above the L(r)−r function at CSR (red line), suggesting clustering. Meanwhile, all of the observed L(r)−r values go above of the randomisation envelope, suggesting statistically significant clustering of both functional and nonfunctional waterpoints in Osun\n\n\n\n\nIn the code chunk below, st_knn() of sfdep package is used to determine the k (i.e. 6) nearest neighbours for given point geometry.\n\nnb <- include_self(\n  st_knn(st_geometry(wp_Osun), 6))\n\nst_kernel_weights() of sfdep package is used to derive a weights list by using a kernel function.\n\nwt <- st_kernel_weights(nb, \n                        wp_Osun, \n                        \"gaussian\", \n                        adaptive = TRUE)\n\nTo compute LCLQ by using sfdep package, the reference point data must be in either character or vector list. The code chunks below are used to prepare two vector lists. One of FunctionalWaterpoint and NonFunctionalWaterpoint are called A and B respectively.\n\nFunctionalWaterpoint <- wp_Osun %>%\nfilter(status_group == \"Functional\")\nA<- FunctionalWaterpoint$status_group\n\n\nNonFunctionalWaterpoint <- wp_Osun %>%\nfilter(status_group == \"Nonfunctional\")\nB <- NonFunctionalWaterpoint$status_group\n\nlocal_colocation() us used to compute the LCLQ values for each NonFunctional water point event.\n\nLCLQ <- local_colocation(B, A, nb, wt, 49)\n\nJoining output table\n\nLCLQ_waterpoint <- cbind(wp_Osun, LCLQ)\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(NGA_Osun) +\n  tm_polygons() +\ntm_shape(LCLQ_waterpoint)+ \n  tm_dots(col = \"p_sim_Functional\",\n             size = 0.01,\n             border.col = \"black\",\n             border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(8, 16))\n\n\n\n\n\n\nFrom the graph, the water point with p-value is small (less than 0.05) is highlighted in color, for the above code, we use non-functional waterpoint as our Category of Interest, the point highlighted in yellow color means that the actual co-location quotient for those nonfunctional water points is statistically significant. Those non-functional water point are surrounded with functional water points and should be carefully examined"
  },
  {
    "objectID": "WeeklyExercise/week2/Handon2/handon2.html",
    "href": "WeeklyExercise/week2/Handon2/handon2.html",
    "title": "In-class Exercise2:Geospatial Data Wrangling",
    "section": "",
    "text": "mpsz = st_read(dsn = \"C:/Quanfang777/IS415-GAA/WeeklyExercise/week2/Handon2/Data/geospatial\",\nlayer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week2\\Handon2\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ncyclingpath = st_read(dsn = \"C:/Quanfang777/IS415-GAA/WeeklyExercise/week2/Handon2/Data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week2\\Handon2\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n st_read(\"C:/Quanfang777/IS415-GAA/WeeklyExercise/week2/Handon2/Data/geospatial/preschools-location.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week2\\Handon2\\Data\\geospatial\\preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\npreschool = st_read(\"C:/Quanfang777/IS415-GAA/WeeklyExercise/week2/Handon2/Data/geospatial/preschools-location.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week2\\Handon2\\Data\\geospatial\\preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nhead(mpsz, n=5) \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\npreschool3414 <- st_transform(preschool, \n                              crs = 3414)\n\n\npreschool3414 <- st_transform(preschool, \n                              crs = 3414)\n\n\nlistings <- read_csv(\"C:/Quanfang777/IS415-GAA/WeeklyExercise/week2/Handon2/Data/aspatial/listings.csv\")\n\nRows: 4161 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlist(listings) \n\n[[1]]\n# A tibble: 4,161 × 18\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   145\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    85\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    85\n 5 275344 15 mins… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    49\n 6 289234 Booking…  367042 Belinda East R… Tampin…    1.34    104. Privat…   184\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    79\n 8 324945 Cozy Bl… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    49\n 9 330089 Cozy Bl… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    55\n10 330095 10 mins… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    55\n# … with 4,151 more rows, 8 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>,\n#   number_of_reviews_ltm <dbl>, license <chr>, and abbreviated variable names\n#   ¹​host_name, ²​neighbourhood_group, ³​neighbourhood, ⁴​latitude, ⁵​longitude,\n#   ⁶​room_type\n\n\n\nlistings_sf <- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\n\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]\n\n\n\nmpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    3.00    5.96    9.00   58.00 \n\n\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           58\n\n\n\nmpsz3414$Area <- mpsz3414 %>%\n  st_area()\n\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "WeeklyExercise/week2/In-Class_Ex02/Week2_Inclass.html",
    "href": "WeeklyExercise/week2/In-Class_Ex02/Week2_Inclass.html",
    "title": "Week3_Inclass",
    "section": "",
    "text": "Handling Geospatial Data\n\nImport the geo boundaries dataset\n\ngeoNGA <- st_read(\"Data/geospatial/\",layer=\"geoBoundaries-NGA-ADM2\") %>%\n  st_transform(crs=26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week2\\In-Class_Ex02\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n#read data in use st_read, if it is a shapefile, exclude the extention,look at the prj format, it is WGS 84, so we need to transfer it into Nigeria CRS.\n\n\nwp_nga <- read_csv(\"Data/aspatial/WPdx.csv\")%>% filter(`#clean_country_name`==\"Nigeria\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 406566 Columns: 70\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (43): #source, #report_date, #status_id, #water_source_clean, #water_sou...\ndbl (23): row_id, #lat_deg, #lon_deg, #install_year, #fecal_coliform_value, ...\nlgl  (4): #rehab_year, #rehabilitator, is_urban, latest_record\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nview the data and see if we can keep the data size small -> we only need #status_clean\n\nview(wp_nga)\n\nConverting water point data into sf point features (notice we have a variable of New Geo referenced column, which provides us WKT, well-known text which allows us to store coordinate information in a single ( )\n\nwp_nga$Geometry = st_as_sfc(wp_nga$'New Georeferenced Column')\nwp_nga\n\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nAs aspatial file don’t have crs information, so we need to assign it\nWhen handling aspatial data, first, understand the data type, then assign crs, if the original file is wgs84, then assign 4326 to it\n\nwp_sf <- st_sf(wp_nga,crs=4326)\nwp_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nThen transform to Nigeria CRS!\n\nwp_sf <- wp_sf %>% st_transform(crs=26392)\n\n\n\n\nImport the NGA dataset\n\nNGA <- st_read(\"data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week2\\In-Class_Ex02\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\nData Cleaning: Excluding redundant fileds\n\nNGA <- NGA%>% select(c(3:4,8:9))\n#select for column, filter for row\n\nChecking for duplicate name\n\nNGA$ADM2_EN[duplicated(NGA$ADM22_EN)==TRUE]\n\ncharacter(0)\n\n\n\n# Get all the duplicated LGA names\nduplicated_LGA <- NGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n# Get all the indices with names that are included in the duplicated LGA names\nduplicated_indices <- which(NGA$ADM2_EN %in% duplicated_LGA)\n\n# For every index in the duplicated_indices, concatenate the two columns with a comma\nfor (ind in duplicated_indices) {\n  NGA$ADM2_EN[ind] <- paste(NGA$ADM2_EN[ind], NGA$ADM1_EN[ind], sep=\", \")\n}\n\n\nfreq(data=wp_sf,input=\n       '#status_clean')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                             <NA>     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nreplace all the record of NA to ‘unknown’\n\nwp_sf_nga <- wp_sf %>% rename(status_clean='#status_clean')%>% select (status_clean) %>% mutate(status_clean=replace_na(status_clean,\"unknown\"))\n\nExtract Water Point Data (For Functional, Non-functional, Unknown respectively)\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\"Functional but not in use\",\"Functional but needs repair\"))\n\n\nwp_nonfunctional<- wp_sf_nga %>% filter(status_clean %in% c(\"Abandoned/Decommissioned\",\"Aboundoned\",\"Non-Functional due to dry season\",\"Non-Fuctional\",\"Non Functional due to dry season\"))\n\n\nwp_unknown<- wp_sf_nga %>% filter(status_clean == 'unknown')\n\n\n\nPerform a quick EDA\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00\n\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1 Non-Functional due to dry season      2403      91.13           91.13\n2         Abandoned/Decommissioned       234       8.87          100.00\n\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\n\n\n\n  status_clean frequency percentage cumulative_perc\n1      unknown     10656        100             100\n\n\nFind out the number of total, functional, nonfunctional and unknown water points in each LGA\n\nNGA_wp <- NGA %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, wp_unknown)))\n\nVisualizing attributes\n\nggplot(data=NGA_wp,aes(x=total_wp))+geom_histogram(bins=20,color=\"black\",fill=\"light blue\") + geom_vline(aes(xintercept=mean(total_wp,na.rm=T)),color=\"red\",linetype=\"dashed\",size=0.8)+ggtitle(\"Distribution of total water points by LGA\")+xlab(\"No.of water points\")+ylab(\"No.of\\nLGAs\")+theme(axis.title.y=element_text(angle = 0))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nSave the sf dataframe into rds format\n\nwrite_rds(NGA_wp,\"Data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "WeeklyExercise/week3/Week3_handon.html",
    "href": "WeeklyExercise/week3/Week3_handon.html",
    "title": "Week3_Handon",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "WeeklyExercise/week3/Week3_handon.html#choropleth-mapping",
    "href": "WeeklyExercise/week3/Week3_handon.html#choropleth-mapping",
    "title": "Week3_Handon",
    "section": "Choropleth Mapping",
    "text": "Choropleth Mapping\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nDrawing a base map\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nGet some descriptive statistics\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMap Layouts\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "WeeklyExercise/week3/Week3_Inclass/Week3_Inclass.html",
    "href": "WeeklyExercise/week3/Week3_Inclass/Week3_Inclass.html",
    "title": "Week3_Inclass",
    "section": "",
    "text": "Handling Geospatial Data\n\nImport the geo boundaries dataset\n\ngeoNGA <- st_read(\"Data/geospatial/\",layer=\"geoBoundaries-NGA-ADM2\") %>%\n  st_transform(crs=26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week3\\Week3_Inclass\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n#read data in use st_read, if it is a shapefile, exclude the extention,look at the prj format, it is WGS 84, so we need to transfer it into Nigeria CRS.\n\n\nwp_nga <- read_csv(\"Data/aspatial/WPdx.csv\")%>% filter(`#clean_country_name`==\"Nigeria\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 406566 Columns: 70\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (43): #source, #report_date, #status_id, #water_source_clean, #water_sou...\ndbl (23): row_id, #lat_deg, #lon_deg, #install_year, #fecal_coliform_value, ...\nlgl  (4): #rehab_year, #rehabilitator, is_urban, latest_record\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nview the data and see if we can keep the data size small -> we only need #status_clean\n\nview(wp_nga)\n\nConverting water point data into sf point features (notice we have a variable of New Geo referenced column, which provides us WKT, well-known text which allows us to store coordinate information in a single ( )\n\nwp_nga$Geometry = st_as_sfc(wp_nga$'New Georeferenced Column')\nwp_nga\n\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nAs aspatial file don’t have crs information, so we need to assign it\nWhen handling aspatial data, first, understand the data type, then assign crs, if the original file is wgs84, then assign 4326 to it\n\nwp_sf <- st_sf(wp_nga,crs=4326)\nwp_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nThen transform to Nigeria CRS!\n\nwp_sf <- wp_sf %>% st_transform(crs=26392)\n\n\n\n\nImport the NGA dataset\n\nNGA <- st_read(\"data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week3\\Week3_Inclass\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\nData Cleaning: Excluding redundant fileds\n\nNGA <- NGA%>% select(c(3:4,8:9))\n#select for column, filter for row\n\nChecking for duplicate name\n\nNGA$ADM2_EN[duplicated(NGA$ADM22_EN)==TRUE]\n\ncharacter(0)\n\n\n\n# Get all the duplicated LGA names\nduplicated_LGA <- NGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n# Get all the indices with names that are included in the duplicated LGA names\nduplicated_indices <- which(NGA$ADM2_EN %in% duplicated_LGA)\n\n# For every index in the duplicated_indices, concatenate the two columns with a comma\nfor (ind in duplicated_indices) {\n  NGA$ADM2_EN[ind] <- paste(NGA$ADM2_EN[ind], NGA$ADM1_EN[ind], sep=\", \")\n}\n\n\nfreq(data=wp_sf,input=\n       '#status_clean')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                             <NA>     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nreplace all the record of NA to ‘unknown’\n\nwp_sf_nga <- wp_sf %>% rename(status_clean='#status_clean')%>% select (status_clean) %>% mutate(status_clean=replace_na(status_clean,\"unknown\"))\n\nExtract Water Point Data (For Functional, Non-functional, Unknown respectively)\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\"Functional but not in use\",\"Functional but needs repair\"))\n\n\nwp_nonfunctional<- wp_sf_nga %>% filter(status_clean %in% c(\"Abandoned/Decommissioned\",\"Aboundoned\",\"Non-Functional due to dry season\",\"Non-Fuctional\",\"Non Functional due to dry season\"))\n\n\nwp_unknown<- wp_sf_nga %>% filter(status_clean == 'unknown')\n\n\n\nPerform a quick EDA\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00\n\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1 Non-Functional due to dry season      2403      91.13           91.13\n2         Abandoned/Decommissioned       234       8.87          100.00\n\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\n\n\n\n  status_clean frequency percentage cumulative_perc\n1      unknown     10656        100             100\n\n\nFind out the number of total, functional, nonfunctional and unknown water points in each LGA\n\nNGA_wp <- NGA %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, wp_unknown)))\n\nVisualizing attributes\n\nggplot(data=NGA_wp,aes(x=total_wp))+geom_histogram(bins=20,color=\"black\",fill=\"light blue\") + geom_vline(aes(xintercept=mean(total_wp,na.rm=T)),color=\"red\",linetype=\"dashed\",size=0.8)+ggtitle(\"Distribution of total water points by LGA\")+xlab(\"No.of water points\")+ylab(\"No.of\\nLGAs\")+theme(axis.title.y=element_text(angle = 0))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nSave the sf dataframe into rds format\n\nwrite_rds(NGA_wp,\"Data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "WeeklyExercise/week4/Hands-on_Ex04/Handon_Ex04.html",
    "href": "WeeklyExercise/week4/Hands-on_Ex04/Handon_Ex04.html",
    "title": "Handon_Ex04",
    "section": "",
    "text": "Using appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nMeanwhile, to answer these questions:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?\n\n\n\n\nTo answer the question, here are the dataset to use:\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)\n\n\n\n\n\n\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week4\\Hands-on_Ex04\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week4\\Hands-on_Ex04\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week4\\Hands-on_Ex04\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nmpsz3414 <- st_set_crs(mpsz_sf, 3414) \n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\n{sg_sf3414 <- st_set_crs(sg_sf, 3414)}\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\n\n\n\n\n# the crs is correctly assigned \nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\n\nst_crs(sg_sf3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(mpsz3414)+ tm_polygons() + tm_shape(childcare_sf) + tm_dots()\n\n\n\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n\n\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\n\n\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\n\n\n\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\n\n\n5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary, so we can covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin <- as(sg_sp, \"owin\")\n\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\n\n\n\n\n\n6.1 Kernel Density Estimation\n\n\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\n\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG_600)\n\n\n\n\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not 0\nor 1)\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n6.4 Converting gridded output into raster\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\n\n\n\n6.5 Assigning projection systems\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\nVariable(s) \"v\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n6.7 Comparing Spatial Point Patterns using KDE\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\n\n\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 31 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 33 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 31 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 32 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.94873, p-value = 0.12\nalternative hypothesis: two-sided\n\n\n\n\n\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.79269, p-value = 0.002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "WeeklyExercise/week4/InClass_Ex04/InClass_Ex04.html#installing-and-loading-the-r-packages",
    "href": "WeeklyExercise/week4/InClass_Ex04/InClass_Ex04.html#installing-and-loading-the-r-packages",
    "title": "InClass_Ex04",
    "section": "Installing and Loading the R packages",
    "text": "Installing and Loading the R packages\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "WeeklyExercise/week4/InClass_Ex04/InClass_Ex04.html#importing-the-spatial-data",
    "href": "WeeklyExercise/week4/InClass_Ex04/InClass_Ex04.html#importing-the-spatial-data",
    "title": "InClass_Ex04",
    "section": "Importing the spatial data",
    "text": "Importing the spatial data\n\n#chunk2\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week4\\InClass_Ex04\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week4\\InClass_Ex04\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\n##hellp\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week4\\InClass_Ex04\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz3414 <- st_set_crs(mpsz_sf, 3414) \n\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\ntmap_mode(\"plot\")\n\ntm_shape(mpsz3414)+ tm_polygons() + tm_shape(childcare_sf) + tm_dots()\n\n\n\n\n\ntmap_mode('view')\ntm_shape(childcare_sf)+tm_dots(alpha=0.5,size=0.01)+tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "WeeklyExercise/week5/InClass_Ex05/data/stores.html",
    "href": "WeeklyExercise/week5/InClass_Ex05/data/stores.html",
    "title": "IS415_GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>"
  },
  {
    "objectID": "WeeklyExercise/week5/InClass_Ex05/data/study_area.html",
    "href": "WeeklyExercise/week5/InClass_Ex05/data/study_area.html",
    "title": "IS415_GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>"
  },
  {
    "objectID": "WeeklyExercise/week5/InClass_Ex05/InClass_Ex05.html",
    "href": "WeeklyExercise/week5/InClass_Ex05/InClass_Ex05.html",
    "title": "InClass_Ex05",
    "section": "",
    "text": "studyArea <- st_read(dsn = 'data',layer=\"study_area\")%>% st_transform(crs=3829)\n\nReading layer `study_area' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week5\\InClass_Ex05\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\n\n\nstores <- st_read(dsn = 'data',layer=\"stores\")%>% st_transform(crs=3829)\n\nReading layer `stores' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week5\\InClass_Ex05\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97\n\n\nVisualising the sf layers\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(studyArea)+tm_polygons()+tm_shape(stores)+tm_dots(col = \"Name\",size = 0.01,border.col=\"black\",border.lwd=0.5\n)+\n  tm_view(set.zoom.limits = c(12,16))\n\n\n\n\n\n\nLocal Colocation Quotients (LCLQ)\nPreparing nearest neighbours list\n\nnb <- include_self(st_knn(st_geometry(stores),6)\n                   )\n\nComputing kernel weights\n\nwt <- st_kernel_weights(nb,stores,\"gaussian\")\n\nWarning in spdep::knearneigh(pnts, k): knearneigh: identical points found\n\n\nWarning in spdep::knearneigh(pnts, k): knearneigh: kd_tree not available for\nidentical points\n\n\nPreparing the vector list\n\nFamilyMart <- stores %>% filter(Name == \"Family Mart\")\nA <- FamilyMart$Name\n\n\nSevenEleven <- stores %>% filter(Name==\"7-Eleven\")\nB<- SevenEleven$Name\n\nComputing LCLQ\n\nLCLQ <-local_colocation(A,B,nb,wt,49)\n\nJoining output table\n\nLCLQ_stores <-cbind(stores,LCLQ)\n\nPlotting LCLQ values\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(studyArea) +\n  tm_polygons() +\ntm_shape(LCLQ_stores)+ \n  tm_dots(col = \"X7.Eleven\",\n             size = 0.01,\n             border.col = \"black\",\n             border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12, 16))"
  },
  {
    "objectID": "WeeklyExercise/week6/Hands-on_Ex06/Handon_Ex06.html",
    "href": "WeeklyExercise/week6/Hands-on_Ex06/Handon_Ex06.html",
    "title": "Handon_Ex06",
    "section": "",
    "text": "Learning objective:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package.\n\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan's local development indicators in 2012.\n\n\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week6\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)  #why six column\n\nJoining, by = \"County\"\n\n\n\n\n\nbasemap <- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n#this showing the neighour of city id 1\n\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen's method are 20981, 34592, 24473, 21311 and 22879 respectively.\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=\"W\"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors' values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we'll stick with the style=\"W\" option for simplicity's sake but note that other more robust options are available, notably style=\"B\".\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nThe code chunk below performs permutation test for Moran's I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary's C. The plot() of base Graph is then used to plot the output.\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)"
  },
  {
    "objectID": "WeeklyExercise/week6/InClass_Ex06/InClass_Ex06.html",
    "href": "WeeklyExercise/week6/InClass_Ex06/InClass_Ex06.html",
    "title": "InClass_Ex06",
    "section": "",
    "text": "Import shapefile into r environment\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week6\\InClass_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport csv file into r environment\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nPerforming relational join\n\n#SF dataframe + tb dataframe\nhunan_GDPPC <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)\n\nJoining, by = \"County\"\n\n#need to specify the joined field if the case different, R is very sensitive to uppercase/lowercase, need to make sure the column value are standardize\n\nPlotting a Choropleth map\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hunan_GDPPC)+\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDP per district\") +\n  tm_layout(main.title = \"Distribution of GDPPC by district\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = TRUE) +\n  tm_borders(alpha = 0.4) +\n  tm_compass(type=\"8star\", size = 1) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\nLegend labels were too wide. The labels have been resized to 0.56, 0.52, 0.52, 0.52, 0.52. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\nComputing Contiguity neighbours method\n\ncn_queen <- hunan_GDPPC %>% mutate(nb=st_contiguity(geometry),.before = 1)\n\n\ncn_roook <- hunan_GDPPC %>% mutate(nb=st_contiguity(geometry),queen=FALSE, .before = 1)\n\nComputing Contiguity Spatial Weights\n\nwm_q <- hunan_GDPPC %>% mutate(nb=st_contiguity(geometry),wt = st_weights(nb), .before = 1)"
  },
  {
    "objectID": "WeeklyExercise/week7/Hands-on_Ex07/Handon_Ex07.html",
    "href": "WeeklyExercise/week7/Hands-on_Ex07/Handon_Ex07.html",
    "title": "Handon_Ex07",
    "section": "",
    "text": "Learn compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package\n\n\n\n\n\nIn spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\nGetting the Data Into R Environment\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week7\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n\nJoining, by = \"County\"\n\n\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\nLearn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\nComputing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nComputing Monte Carlo Moran’s I\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")\n\n\n\n\n\n\n\n\nLearn how to perform Geary’s c statistics testing by using appropriate functions of spdep package\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\nCompute Moran’s I correlogram\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section will illustrate how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\nComputing local Moran’s I To compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips <- order(hunan$County)\nlocalMI <- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nocalmoran() function returns a matrix of values whose columns are:\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\nMapping the local Moran’s I\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nMapping local Moran’s I values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\nPlotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci <- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\nPlotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% \n  as.vector \n\n\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I <- localMI[,1]   \nsignif <- 0.05       \nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4    \nquadrant[localMI[,5]>signif] <- 0\n\n\n\n\n\n\n\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\ncoords <- cbind(longitude, latitude)\n\n\n\n\nFirstly, we need to determine the upper limit for distance band by using the steps below:\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nnb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014\n\n\n\n\n\n\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Takehome_Exercise/Takehome_Exercise2/Takehome_Ex02.html",
    "href": "Takehome_Exercise/Takehome_Exercise2/Takehome_Ex02.html",
    "title": "Takehome_Ex02",
    "section": "",
    "text": "Since late December 2019, an outbreak of a novel coronavirus disease (COVID-19; previously known as 2019-nCoV) was reported in Wuhan, China, which had subsequently affected 210 countries worldwide. In general, COVID-19 is an acute resolved disease but it can also be deadly, with a 2% case fatality rate.\nThe COVID-19 vaccination in Indonesia is an ongoing mass immunisation in response to the COVID-19 pandemic in Indonesia. On 13 January 2021, the program commenced when President Joko Widodo was vaccinated at the presidential palace. In terms of total doses given, Indonesia ranks third in Asia and fifth in the world.\nAccording to wikipedia, as of 5 February 2023 at 18:00 WIB (UTC+7), 204,266,655 people had received the first dose of the vaccine and 175,131,893 people had been fully vaccinated; 69,597,474 of them had been inoculated with the booster or the third dose, while 1,585,164 had received the fourth dose. Jakarta has the highest percentage of population fully vaccinated with 103.46%, followed by Bali and Special Region of Yogyakarta with 85.45% and 83.02% respectively.\nDespite its compactness, the cumulative vaccination rate are not evenly distributed within DKI Jakarta. The question is where are the sub-districts with relatively higher number of vaccination rate and how they changed over time.\n\n\n\n\nApply appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatio-temporal trends of COVID-19 vaccination in DKI Jakarta.\nReveal the spatio-temporal patterns of COVID-19 cases in the DKI Jakarta province on a sub-district level\nExamine sub-districts that have a higher value of confirmed cases and deaths relative to other sub-districts\n\n\n\n\n\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr,readxl,dplyr,lubridate,stringr,sfdep,plotly)\n\n\n\n\n\ndatasets <- data.frame(\n  Type=c(\"Geospatial\",\n         \"Aspatial\"),\n  Name=c(\"[Batas Desa Provinsi DKI Jakarta] Link:(https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html)\",\n         \"[Standar Kelurahan Data Corona (Monthly)] Link:(https://riwayat-file-covid-19-dki-jakarta-jakartagis.hub.arcgis.com/)\"),\n  Format=c(\"Shapefile\", \n           \".xlsx\"),\n  Description=c(\"Sub-districts in DKI Jakarta\",\n                \"Sub-district level data of daily COVID-19 cases in DKI Jakarta  \n                between March 2020~July 2021\")\n  )\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nkable(head(datasets), caption=\"Datasets Used\") %>%\n  kable_material(\"hover\", latex_options=\"scale_down\")\n\n\n\nDatasets Used\n \n  \n    Type \n    Name \n    Format \n    Description \n  \n \n\n  \n    Geospatial \n    [Batas Desa Provinsi DKI Jakarta] Link:(https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html) \n    Shapefile \n    Sub-districts in DKI Jakarta \n  \n  \n    Aspatial \n    [Standar Kelurahan Data Corona (Monthly)] Link:(https://riwayat-file-covid-19-dki-jakarta-jakartagis.hub.arcgis.com/) \n    .xlsx \n    Sub-district level data of daily COVID-19 cases in DKI Jakarta  \n                between March 2020~July 2021 \n  \n\n\n\n\n\n\n\n\nLet’s import our geospatial data and only select necessary field, which is first 9 field\n\njakarta <- st_read(dsn=\"data/geospatial\",\n                      layer=\"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\") %>% select(0:9)\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\Quanfang777\\IS415-GAA\\Takehome_Exercise\\Takehome_Exercise2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\nFrom the data we learnt that the CRS is in WGS 84, but we should change it to national CRS of Indonesia, the ESPC code should be 23845\n\njakarta <- st_transform(jakarta, 23845) \n\nLet’s double check if CRS has been properly assigned\n\nst_crs(jakarta)\n\nCoordinate Reference System:\n  User input: EPSG:23845 \n  wkt:\nPROJCRS[\"DGN95 / Indonesia TM-3 zone 54.1\",\n    BASEGEOGCRS[\"DGN95\",\n        DATUM[\"Datum Geodesi Nasional 1995\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4755]],\n    CONVERSION[\"Indonesia TM-3 zone 54.1\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",139.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9999,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",200000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",1500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre.\"],\n        AREA[\"Indonesia - onshore east of 138°E.\"],\n        BBOX[-9.19,138,-1.49,141.01]],\n    ID[\"EPSG\",23845]]\n\n\nYes, it has been correctly assigned\n\n\nFor geospatial analysis, it is always important for us to check if there is any invalid geometries and missing value\n\n\n\n\nlength(which(st_is_valid(jakarta) == FALSE))\n\n[1] 0\n\n\nThere are no invalid geometries.\n\n\n\n\njakarta[rowSums(is.na(jakarta))!=0,]\n\nSimple feature collection with 2 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -3623599 ymin: 691982.5 xmax: -3620985 ymax: 693163.1\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\n    OBJECT_ID KODE_DESA             DESA   KODE    PROVINSI KAB_KOTA KECAMATAN\n243     25645  31888888     DANAU SUNTER 318888 DKI JAKARTA     <NA>      <NA>\n244     25646  31888888 DANAU SUNTER DLL 318888 DKI JAKARTA     <NA>      <NA>\n    DESA_KELUR JUMLAH_PEN                       geometry\n243       <NA>          0 MULTIPOLYGON (((-3620985 69...\n244       <NA>          0 MULTIPOLYGON (((-3622382 69...\n\n\nwe could observe that the row with id 243,244 are the rows with missing values, so let’s remove them\n\njakarta <- na.omit(jakarta,c(\"DESA_KELUR\"))\n\n\n\n\n\n\nbasemap <- tm_shape(jakarta) +\n  tm_polygons()\nbasemap\n\n\n\n\nwe found that there are some outer island that are not relevant to our analysis, so let’s remove them and keep the mainland only\nLet’s carefully examine the data, to remove the outer island, we could look at the city level, which is ‘KAB_KOT’. To understand the ‘KAB_KOT’ let’s follow the code below:\n\nunique(jakarta$\"KAB_KOTA\")\n\n[1] \"JAKARTA BARAT\"    \"JAKARTA PUSAT\"    \"KEPULAUAN SERIBU\" \"JAKARTA UTARA\"   \n[5] \"JAKARTA TIMUR\"    \"JAKARTA SELATAN\" \n\n\nwe could notice that all cities within Jakarta have a JAKARTA prefix, only “KEPULAUAN SERIBU” is different, by researching “KEPULAUAN SERIBU” we understand it means”Thousand Island” and it refers to the outer island, so let’s remove it:\n\njakarta <- filter(jakarta, KAB_KOTA != \"KEPULAUAN SERIBU\")\n\nLet’s check our basemap!\n\nbasemap <- tm_shape(jakarta) +\n  tm_polygons()\nbasemap\n\n\n\n\nIt looks good! The last step is to rename the column to English\n\njakarta <-jakarta %>% \n  dplyr::rename(\n    Object_ID=OBJECT_ID,\n    Province=PROVINSI, \n    City=KAB_KOTA, \n    District=KECAMATAN, \n    Village_Code=KODE_DESA, \n    Village=DESA, \n    Sub_District=DESA_KELUR,\n    Code=KODE, \n    Total_Population=JUMLAH_PEN\n    )\n\n\n\nFor proper and meaningful data analysis, we always need to examine the necessary column to keep and remove the unnecessary ones to improve the performance as well as computing efficiency\nLet’s take a look at our original datasets by importing one of our aspatial data\n\nAug2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 August 2021).xlsx\")\n\nview the one of the excel file to understand the data\n\nview(Aug2022)\n\nThe necessary columns needed are shown as below: (other than the fields the excel file already contained, we also need a column called Date, which our original excel file not contained but necessary for us to include to analyze the spatio-temporal trends of COVID-19 vaccination in DKI Jakarta.\n\n\n\nIndex\nOriginal Name\nTranslated Name\n\n\n\n\n1\nObject_ID\nObject_ID\n\n\n2\nPROVINSI\nProvince\n\n\n3\nKAB_KOTA\nCity\n\n\n4\nKECAMATAN\nDistrict\n\n\n5\nDESA_KELUR\nSub-District\n\n\n6\nKODE_DESA\nVillage_Code\n\n\n7\nKODE\nCode\n\n\n8\nVillage\nDESA\n\n\n9\nJUMLAH_PEN\nTotal_Population\n\n\n\nNow, let’s prepare our aspatial data\n\n# Set the path to the folder where the Excel files are stored\nfolder_path <- \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial\"\n\n\n#Get a list of all the Excel files in the folder\nfile_list <- list.files(folder_path, pattern = \"*.xlsx\", full.names = TRUE) \n\n\n#check if the file list retrieved properly\nfile_list\n\n [1] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 April 2022).xlsx\"    \n [2] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 August 2021).xlsx\"   \n [3] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 December 2021).xlsx\" \n [4] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 February 2022).xlsx\" \n [5] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 January 2022).xlsx\"  \n [6] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 July 2021).xlsx\"     \n [7] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 June 2022).xlsx\"     \n [8] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 May 2022).xlsx\"      \n [9] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 November 2021).xlsx\" \n[10] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 October 2021).xlsx\"  \n[11] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (01 September 2021).xlsx\"\n[12] \"C:/Quanfang777/IS415-GAA/Takehome_Exercise/Takehome_Exercise2/data/aspatial/Data Vaksinasi Berbasis Kelurahan (02 March 2022).xlsx\"    \n\n\nUse lubridate to convert date data : please refer to this website\n\n# Create an empty dataframe to store the combined data\nvaccination_data <- data.frame()\n\n# Loop through each file in the list, read the data, and append it to the combined data\nfor (file in file_list) {\n  sheet_name <- \"Data Kelurahan\" \n  date <- dmy(str_extract(file, \"\\\\d{2} [[:alpha:]]+ \\\\d{4}\"))\n  data <- read_excel(file, sheet =\"Data Kelurahan\")\n  data$date <- date\n   vaccination_data <- bind_rows( vaccination_data, data)\n}\n\nNow, let’s only keep the column used for analysis:\n\n vaccination_data <-  vaccination_data %>%\n  select(1:6, \"date\")\n\n\n view(vaccination_data )\n\nRename the column to English for further analysis\n\nvaccination_data <- vaccination_data %>% \n  dplyr::rename(\n    Family_Code = \"KODE KELURAHAN\",\n    City = \"WILAYAH KOTA\",\n    District=KECAMATAN, \n    Sub_District= KELURAHAN,\n    Target=SASARAN, \n    Yet_to_be_Vaccinated=\"BELUM VAKSIN\",\n    )\n\nRemove the missing value\n\nvaccination_data[rowSums(is.na(vaccination_data))!=0,]\n\n     Family_Code City District Sub_District  Target Yet_to_be_Vaccinated\n1           <NA> <NA>     <NA>        TOTAL 8941211              1481006\n269         <NA> <NA>     <NA>        TOTAL 8941211              4399496\n537         <NA> <NA>     <NA>        TOTAL 8941211              1718787\n805         <NA> <NA>     <NA>        TOTAL 8941211              1536737\n1073        <NA> <NA>     <NA>        TOTAL 8941211              1620250\n1341        <NA> <NA>     <NA>        TOTAL 7739060              5041111\n1609        <NA> <NA>     <NA>        TOTAL 8941211              1444901\n1877        <NA> <NA>     <NA>        TOTAL 8941211              1455001\n2145        <NA> <NA>     <NA>        TOTAL 8941211              1875655\n2413        <NA> <NA>     <NA>        TOTAL 8941211              2221074\n2681        <NA> <NA>     <NA>        TOTAL 8941211              3259430\n2949        <NA> <NA>     <NA>        TOTAL 8941211              1516200\n           date\n1    2022-04-01\n269  2021-08-01\n537  2021-12-01\n805  2022-02-01\n1073 2022-01-01\n1341 2021-07-01\n1609 2022-06-01\n1877 2022-05-01\n2145 2021-11-01\n2413 2021-10-01\n2681 2021-09-01\n2949 2022-03-02\n\n\n\nvaccination_data <- na.omit(vaccination_data,c(\"Family_code\"))\n\nJoin the data\n\ncombined_jakarta <- left_join(jakarta, vaccination_data,\n                              by=c(\n                                \"Sub_District\"=\"Sub_District\")\n                              )\n\n\nview(combined_jakarta)\n\nLet’s plot the combined_jarkarta and check if the data has been combined properly!\n\ntarget_cases = tm_shape(combined_jakarta)+\n  tm_fill(\"Target\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Target\")\n\nyet_to_be_vac = tm_shape(combined_jakarta)+\n  tm_fill(\"Yet_to_be_Vaccinated\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Yet_to_be_Vaccinated\")\n\ntmap_arrange(target_cases, yet_to_be_vac)\n\n\n\n\nHowever, it seems that there are still some missing value, let’s check the column to be joined and see if there is any miss match:\n\nvaccination_subdistrict <- c(vaccination_data$Sub_District)\njakata_subdistrict <- c(jakarta$Sub_District)\n\nunique(vaccination_subdistrict[!(vaccination_subdistrict %in% jakata_subdistrict)])\n\n [1] \"BALE KAMBANG\"          \"HALIM PERDANA KUSUMAH\" \"JATI PULO\"            \n [4] \"KAMPUNG TENGAH\"        \"KERENDANG\"             \"KRAMAT JATI\"          \n [7] \"PAL MERIAM\"            \"PINANG RANTI\"          \"PULAU HARAPAN\"        \n[10] \"PULAU KELAPA\"          \"PULAU PANGGANG\"        \"PULAU PARI\"           \n[13] \"PULAU TIDUNG\"          \"PULAU UNTUNG JAWA\"     \"RAWA JATI\"            \n\n\n\nunique(jakata_subdistrict[!(jakata_subdistrict %in% vaccination_subdistrict)])\n\n[1] \"KRENDANG\"             \"RAWAJATI\"             \"TENGAH\"              \n[4] \"BALEKAMBANG\"          \"PINANGRANTI\"          \"JATIPULO\"            \n[7] \"PALMERIAM\"            \"KRAMATJATI\"           \"HALIM PERDANA KUSUMA\"\n\n\nIt seems that although the names for Sub_District of both datasets refer the same place but they spell differently, one dataset has space to split the name, the other is not! so it couldn’t be identified as the same, so let’s update the name to be the same\n\njakarta$Sub_District[jakarta$Sub_District == 'BALEKAMBANG'] <- 'BALE KAMBANG'\njakarta$Sub_District[jakarta$Sub_District == 'HALIM PERDANA KUSUMA'] <- 'HALIM PERDANA KUSUMAH'\njakarta$Sub_District[jakarta$Sub_District == 'JATIPULO'] <- 'JATI PULO'\njakarta$Sub_District[jakarta$Sub_District == 'TENGAH'] <- 'KAMPUNG TENGAH'\njakarta$Sub_District[jakarta$Sub_District == 'KRAMATJATI'] <- 'KRAMAT JATI'\njakarta$Sub_District[jakarta$Sub_District == 'KRENDANG'] <- 'KERENDANG'\njakarta$Sub_District[jakarta$Sub_District == 'PALMERIAM'] <- 'PAL MERIAM'\njakarta$Sub_District[jakarta$Sub_District == 'PINANGRANTI'] <- 'PINANG RANTI'\njakarta$Sub_District[jakarta$Sub_District == 'RAWAJATI'] <- 'RAWA JATI'\n\nDo the joii\n\ncombined_jakarta <- left_join(jakarta, vaccination_data,\n                              by=c(\n                                \"Sub_District\"=\"Sub_District\")\n                              )\n\n\ntarget_cases = tm_shape(combined_jakarta)+\n  tm_fill(\"Target\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Target\")\n\nyet_to_be_vac = tm_shape(combined_jakarta)+\n  tm_fill(\"Yet_to_be_Vaccinated\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Yet_to_be_Vaccinated\")\n\ntmap_arrange(target_cases, yet_to_be_vac)\n\n\n\n\nNow, there is no miss match!\n\n\n\n\n\n\ncombined_jakarta$Monthly_Vacinnation_Rate <- (combined_jakarta$Target - combined_jakarta$Yet_to_be_Vaccinated) / combined_jakarta$Target\n\nTo plot the monthly vaccination rate, we need to make the each date value as column, we should have the format by running the code below:\n\ncases_rate <- vaccination_data %>%\n  inner_join(jakarta, by=c(\"Sub_District\" = \"Sub_District\")) %>%\n  group_by(Sub_District, date) %>%\n  dplyr::summarise(`Monthly_Vac_R` = ((Target-Yet_to_be_Vaccinated)/Target)) %>%\n  ungroup() %>% pivot_wider(names_from = date,\n              values_from = Monthly_Vac_R)\n\n`summarise()` has grouped output by 'Sub_District'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\ncombined_jakarta <- st_as_sf(combined_jakarta)\n\n# need to join our previous dataframes with the geospatial data to ensure that geometry column is present\ncases_rate <- cases_rate%>% left_join(jakarta, by=c(\"Sub_District\"=\"Sub_District\"))\ncases_rate <- st_as_sf(cases_rate)\n\nLet’s create a function to plot the graphs, so that we can reduce many repetitive work ( Thanks our senior Megan for the code and this clever method!\n\njenks_plot <- function(df, varname) {\n  tm_shape(jakarta) +\n    tm_polygons() +\n  tm_shape(df) +\n    tm_fill(varname, \n          n= 6,\n          style = \"jenks\", \n          title = \"Case Rate\") +\n    tm_layout(main.title = varname,\n          main.title.position = \"center\",\n          main.title.size = 1.2,\n          legend.height = 0.45, \n          legend.width = 0.35,\n          frame = TRUE) +\n    tm_borders(alpha = 0.5)\n}\n\n\nglimpse(cases_rate)\n\nRows: 261\nColumns: 22\n$ Sub_District     <chr> \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\", \"BAM…\n$ `2021-07-01`     <dbl> 0.3491884, 0.3609851, 0.2507751, 0.3385927, 0.3233046…\n$ `2021-08-01`     <dbl> 0.4924208, 0.5327933, 0.3731169, 0.4886177, 0.4781815…\n$ `2021-09-01`     <dbl> 0.6184073, 0.6478336, 0.5716104, 0.6217186, 0.6442838…\n$ `2021-10-01`     <dbl> 0.7224287, 0.7427249, 0.7021394, 0.7440525, 0.7696405…\n$ `2021-11-01`     <dbl> 0.7509083, 0.7774752, 0.7399395, 0.7828138, 0.8097014…\n$ `2021-12-01`     <dbl> 0.7697415, 0.7968755, 0.7668363, 0.8035275, 0.8251474…\n$ `2022-01-01`     <dbl> 0.7891594, 0.8088561, 0.7826236, 0.8174733, 0.8338216…\n$ `2022-02-01`     <dbl> 0.8062388, 0.8167183, 0.7950746, 0.8283429, 0.8449686…\n$ `2022-03-02`     <dbl> 0.8083267, 0.8191008, 0.7971727, 0.8309065, 0.8467187…\n$ `2022-04-01`     <dbl> 0.8113334, 0.8236615, 0.8014033, 0.8338802, 0.8500666…\n$ `2022-05-01`     <dbl> 0.8139224, 0.8262142, 0.8037078, 0.8360336, 0.8531482…\n$ `2022-06-01`     <dbl> 0.8145906, 0.8269970, 0.8049460, 0.8371616, 0.8545178…\n$ Object_ID        <dbl> 25455, 25486, 25605, 25595, 25642, 25531, 25609, 2560…\n$ Village_Code     <chr> \"3172051003\", \"3173041007\", \"3175041005\", \"3175031003…\n$ Village          <chr> \"ANCOL\", \"ANGKE\", \"BALEKAMBANG\", \"BALI MESTER\", \"BAMB…\n$ Code             <dbl> 317205, 317304, 317504, 317503, 317510, 317403, 31750…\n$ Province         <chr> \"DKI JAKARTA\", \"DKI JAKARTA\", \"DKI JAKARTA\", \"DKI JAK…\n$ City             <chr> \"JAKARTA UTARA\", \"JAKARTA BARAT\", \"JAKARTA TIMUR\", \"J…\n$ District         <chr> \"PADEMANGAN\", \"TAMBORA\", \"KRAMATJATI\", \"JATINEGARA\", …\n$ Total_Population <dbl> 29886, 36428, 35376, 11695, 31774, 26261, 29389, 5889…\n$ geometry         <MULTIPOLYGON [m]> MULTIPOLYGON (((-3621016 69..., MULTIPOL…\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntmap_arrange(jenks_plot(cases_rate, \"2021-07-01\"),\n             jenks_plot(cases_rate, \"2021-08-01\"),\n             jenks_plot(cases_rate, \"2021-09-01\"),\n             jenks_plot(cases_rate, \"2021-10-01\"),\n             jenks_plot(cases_rate, \"2021-11-01\"),\n             jenks_plot(cases_rate, \"2021-12-01\"))\n\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntmap_arrange(jenks_plot(cases_rate, \"2022-01-01\"),\n             jenks_plot(cases_rate, \"2022-02-01\"),\n             jenks_plot(cases_rate, \"2022-03-02\"),\n             jenks_plot(cases_rate, \"2022-04-01\"),\n             jenks_plot(cases_rate, \"2022-05-01\"),\n             jenks_plot(cases_rate, \"2022-06-01\"))\n\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nLegend labels were too wide. The labels have been resized to 0.47, 0.47, 0.47, 0.47, 0.47, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLocal Spatial Autocorrelation Statistics is collection of geospatial statistical analysis methods for analysing the location related tendency (clusters or outliers) in the attributes of geographically referenced data (points or areas).\nThese spatial statistics are well suited for:\n\ndetecting clusters or outliers;\nidentifying hot spot or cold spot areas;\nassessing the assumptions of stationarity; and\nidentifying distances beyond which no discernible association obtains.\n\nBelow are the steps to compute Local Gi*\n\n\nFirst we need queen method to derive the contiguity weights.\n\nwm_idw <- combined_jakarta %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nLet’s prepare to visualize Gi* by using a HCSA map:\n\nHCSA <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    Monthly_Vacinnation_Rate, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 3132 features and 26 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -3644275 ymin: 663887.8 xmax: -3606237 ymax: 701380.1\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\n# A tibble: 3,132 × 27\n   gi_star     e_gi   var_gi p_value p_sim p_folde…¹ skewn…² kurto…³ nb    wts  \n     <dbl>    <dbl>    <dbl>   <dbl> <dbl>     <dbl>   <dbl>   <dbl> <nb>  <lis>\n 1    1.45 0.000319 6.24e-11  0.147   0.1       0.05  -0.566   0.474 <int> <dbl>\n 2    1.43 0.000319 6.03e-11  0.152   0.12      0.06  -0.588   0.450 <int> <dbl>\n 3    1.67 0.000318 5.59e-11  0.0940  0.14      0.07   0.136  -0.414 <int> <dbl>\n 4    1.60 0.000318 5.86e-11  0.111   0.1       0.05  -0.108   0.280 <int> <dbl>\n 5    1.48 0.000320 5.43e-11  0.140   0.12      0.06  -0.325  -0.176 <int> <dbl>\n 6    1.32 0.000319 8.05e-11  0.185   0.14      0.07  -0.556  -0.179 <int> <dbl>\n 7    1.36 0.000319 6.92e-11  0.174   0.12      0.06  -0.138  -0.405 <int> <dbl>\n 8    1.37 0.000319 6.93e-11  0.172   0.24      0.12  -0.277  -0.409 <int> <dbl>\n 9    1.51 0.000319 6.12e-11  0.130   0.12      0.06  -0.232  -0.486 <int> <dbl>\n10    1.55 0.000319 5.65e-11  0.121   0.12      0.06  -0.137  -0.534 <int> <dbl>\n# … with 3,122 more rows, 17 more variables: Object_ID <dbl>,\n#   Village_Code <chr>, Village <chr>, Code <dbl>, Province <chr>,\n#   City.x <chr>, District.x <chr>, Sub_District <chr>, Total_Population <dbl>,\n#   Family_Code <chr>, City.y <chr>, District.y <chr>, Target <dbl>,\n#   Yet_to_be_Vaccinated <dbl>, date <date>, geometry <MULTIPOLYGON [m]>,\n#   Monthly_Vacinnation_Rate <dbl>, and abbreviated variable names\n#   ¹​p_folded_sim, ²​skewness, ³​kurtosis\n\n\n\nHCSA_SIG = HCSA %>% filter(gi_star >1.5)\nHCSA_SIG\n\nSimple feature collection with 28 features and 26 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -3627698 ymin: 664154 xmax: -3614259 ymax: 693604.4\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\n# A tibble: 28 × 27\n   gi_star     e_gi   var_gi p_value p_sim p_fold…¹ skewness kurto…² nb    wts  \n *   <dbl>    <dbl>    <dbl>   <dbl> <dbl>    <dbl>    <dbl>   <dbl> <nb>  <lis>\n 1    1.67 0.000318 5.59e-11  0.0940  0.14     0.07  0.136   -0.414  <int> <dbl>\n 2    1.60 0.000318 5.86e-11  0.111   0.1      0.05 -0.108    0.280  <int> <dbl>\n 3    1.51 0.000319 6.12e-11  0.130   0.12     0.06 -0.232   -0.486  <int> <dbl>\n 4    1.55 0.000319 5.65e-11  0.121   0.12     0.06 -0.137   -0.534  <int> <dbl>\n 5    1.56 0.000319 5.69e-11  0.118   0.12     0.06  0.0593  -0.289  <int> <dbl>\n 6    1.99 0.000317 4.96e-11  0.0462  0.04     0.02 -0.263   -0.291  <int> <dbl>\n 7    1.61 0.000320 4.57e-11  0.107   0.08     0.04 -0.488   -0.148  <int> <dbl>\n 8    1.51 0.000321 4.51e-11  0.132   0.06     0.03 -0.627    0.240  <int> <dbl>\n 9    1.59 0.000320 5.21e-11  0.111   0.18     0.09  0.263   -0.108  <int> <dbl>\n10    1.53 0.000320 5.56e-11  0.125   0.16     0.08 -0.00686 -0.0508 <int> <dbl>\n# … with 18 more rows, 17 more variables: Object_ID <dbl>, Village_Code <chr>,\n#   Village <chr>, Code <dbl>, Province <chr>, City.x <chr>, District.x <chr>,\n#   Sub_District <chr>, Total_Population <dbl>, Family_Code <chr>,\n#   City.y <chr>, District.y <chr>, Target <dbl>, Yet_to_be_Vaccinated <dbl>,\n#   date <date>, geometry <MULTIPOLYGON [m]>, Monthly_Vacinnation_Rate <dbl>,\n#   and abbreviated variable names ¹​p_folded_sim, ²​kurtosis\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 <- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of Monthly Vacinnation Rate\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\njakarta_cube <- combined_jakarta %>% select (\"Sub_District\",\"date\",\"Monthly_Vacinnation_Rate\")\n\n\n\n\n\njakarta_st <- spacetime(jakarta_cube , jakarta,\n                      .loc_col = \"Sub_District\",\n                      .time_col = \"date\")\n\n\nis_spacetime_cube(jakarta_st)\n\n[1] TRUE\n\n\n\njakarta_nb <- jakarta_st %>% activate(\"geometry\") %>% mutate (nb=include_self(st_contiguity(geometry)),wt=st_weights(nb))%>% set_wts(\"wt\")%>%set_nbs(\"nb\")\n\n\ngi_stars <- jakarta_nb %>% \n  group_by(date) %>% \n  mutate(gi_star = local_gstar_perm(\n    Monthly_Vacinnation_Rate, nb, wt)) %>% \n  tidyr::unnest(gi_star)\n\nMann-Kendall Test\n\n\n\n\ncbg <- gi_stars %>% \n  ungroup() %>% \n  filter(Sub_District == \"KEAGUNGAN\") |> \n  select(Sub_District,date, gi_star)\n\n\np <- ggplot(data = cbg, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\ncbg %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 6\n      tau    sl     S     D  varS                                       geometry\n    <dbl> <dbl> <dbl> <dbl> <dbl>                             <MULTIPOLYGON [m]>\n1 -0.0606 0.837    -4  66.0  213. (((-3626874 692480.8, -3626854 692420.4, -362…\n\n\nSub_District 2\n\ncbg2 <- gi_stars %>% \n  ungroup() %>% \n  filter(Sub_District == \"KEBON MELATI\") |> \n  select(Sub_District,date, gi_star)\n\n\np <- ggplot(data = cbg2, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\ncbg2 %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 6\n     tau       sl     S     D  varS                                     geometry\n   <dbl>    <dbl> <dbl> <dbl> <dbl>                           <MULTIPOLYGON [m]>\n1 -0.788 0.000470   -52  66.0  213. (((-3626882 686779.9, -3626835 686735.8, -3…\n\n\nSub_District 3\n\ncbg3 <- gi_stars %>% \n  ungroup() %>% \n  filter(Sub_District == \"KEBON KACANG\") |> \n  select(Sub_District,date, gi_star)\n\n\np <- ggplot(data = cbg3, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\ncbg3 %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 6\n     tau       sl     S     D  varS                                     geometry\n   <dbl>    <dbl> <dbl> <dbl> <dbl>                           <MULTIPOLYGON [m]>\n1 -0.788 0.000470   -52  66.0  213. (((-3625808 687465.5, -3625790 687466, -362…\n\n\n\n\n\n\n\nehsa <- gi_stars %>%\n  group_by(Sub_District) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n\n\nemerging <- ehsa %>% \n  arrange(sl, abs(tau)) %>% \n  slice(1:5)\n\n\nehsa <- emerging_hotspot_analysis(\n  x = jakarta_st, \n  .var = \"Monthly_Vacinnation_Rate\", \n  k = 1, \n  nsim = 99\n)\n\n\nehsa <- st_as_sf(ehsa)\n\nCredit:"
  },
  {
    "objectID": "WeeklyExercise/week7/InClass_Ex07/InClass_Ex07.html",
    "href": "WeeklyExercise/week7/InClass_Ex07/InClass_Ex07.html",
    "title": "InClass_Ex07",
    "section": "",
    "text": "Import shapefile into r environment\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Quanfang777\\IS415-GAA\\WeeklyExercise\\week7\\InClass_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nGDPPC <- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nGDPPC_st <- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n\n\nGDPPC_nb <- GDPPC_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n\n\nWarning in st_point_on_surface.sfc(geometry): st_point_on_surface may not give\ncorrect results for longitude/latitude data\n\n\n\ngi_stars <- GDPPC_nb %>% \n  group_by(Year) %>% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %>% \n  tidyr::unnest(gi_star)\n\n\nehsa <- gi_stars %>%\n  group_by(County) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n\n\nehsa <- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99\n)\n\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\nhunan_ehsa <-  left_join(hunan, ehsa, by = c(\"County\" = \"location\"))\n\n\nehsa_sig <- hunan_ehsa  %>%\n  filter(p_value < 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  }
]